# Databricks Post Processor

Sistema profissional de scraping, processamento com IA e integra√ß√£o de posts do blog Databricks.

## Vis√£o Geral

Esta aplica√ß√£o realiza tr√™s opera√ß√µes principais:

1. **Scraping**: Extrai posts da categoria "Platform" do blog Databricks
2. **Processamento IA**: Gera resumos profissionais usando OpenAI GPT
3. **Integra√ß√£o n8n**: Envia posts processados para webhook n8n

## Arquitetura

```
src/
‚îú‚îÄ‚îÄ main.py              # Orquestrador principal
‚îú‚îÄ‚îÄ config.py            # Gerenciamento de configura√ß√µes
‚îú‚îÄ‚îÄ logger.py            # Sistema de logging profissional
‚îú‚îÄ‚îÄ scraper.py           # Web scraping com Selenium
‚îú‚îÄ‚îÄ ai_processor.py      # Processamento com OpenAI
‚îú‚îÄ‚îÄ n8n_integration.py   # Integra√ß√£o webhook n8n
‚îú‚îÄ‚îÄ csv_handler.py       # Opera√ß√µes CSV
‚îú‚îÄ‚îÄ database.py          # Persist√™ncia SQLite
‚îî‚îÄ‚îÄ utils.py             # Utilit√°rios gerais

config.ini              # Configura√ß√µes da aplica√ß√£o
.env                    # Vari√°veis de ambiente (API keys)
```

## Pr√©-requisitos

### Op√ß√£o 1: Docker (Recomendado)

- Docker Engine 20.10+
- Docker Compose 2.0+
- Chave de API OpenAI

### Op√ß√£o 2: Python Nativo

- Python 3.9 ou superior
- Google Chrome instalado
- Chave de API OpenAI
- Acesso ao webhook n8n (opcional)

---

## Instala√ß√£o e Uso

### üê≥ Op√ß√£o 1: Docker (Recomendado)

**In√≠cio R√°pido - 5 Minutos**

#### Linux/Mac:
```bash
# Setup autom√°tico
chmod +x setup_docker.sh
./setup_docker.sh

# Configurar API Key
nano .env
# Adicione: OPENAI_API_KEY=sk-sua-chave-aqui

# Iniciar
docker-compose up -d

# Monitorar
docker-compose logs -f
```

#### Windows (PowerShell):
```powershell
# Setup autom√°tico
.\setup_docker.ps1

# Configurar API Key
notepad .env

# Iniciar
docker-compose up -d

# Monitorar
docker-compose logs -f
```

**Agendamento Autom√°tico**:
- **Padr√£o**: Segunda-feira √†s 08:00
- **Customiza√ß√£o**: Edite `SCHEDULE_CRON` no `.env`
- **Guia Completo**: Ver `DOCKER_QUICKSTART.md`

**Comandos Docker Essenciais**:
```bash
docker-compose up -d          # Iniciar
docker-compose down           # Parar
docker-compose logs -f        # Ver logs
docker-compose ps             # Status
docker-compose restart        # Reiniciar
```

**Executar Manualmente** (fora do agendamento):
```bash
docker-compose exec afn-linkedin-processor python run.py
```

---

### üêç Op√ß√£o 2: Python Nativo

## Instala√ß√£o

### 1. Clone o reposit√≥rio

```bash
git clone <repository-url>
cd Linkedin
```

### 2. Crie ambiente virtual

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Instale depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configure vari√°veis de ambiente

Crie arquivo `.env` na raiz do projeto:

```env
OPENAI_API_KEY=sua_chave_api_aqui
ENVIRONMENT=production
```

### 5. Ajuste configura√ß√µes (opcional)

Edite `config.ini` conforme necess√°rio:

- URLs de scraping
- Configura√ß√µes do Selenium
- Par√¢metros OpenAI
- Webhook n8n

## Uso

### Executar Pipeline Completo

```bash
python run.py
```

Executa todas as fases: scraping ‚Üí processamento ‚Üí integra√ß√£o

**Alternativas**:
```bash
# Como m√≥dulo Python
python -m src.main

# Direto (se PYTHONPATH configurado)
python src/main.py
```

### Executar Fases Individuais

Edite `src/main.py` e escolha o m√©todo desejado:

```python
# Apenas scraping
app.run_scraping()

# Apenas processamento IA
app.run_ai_processing()

# Apenas integra√ß√£o n8n
app.run_n8n_integration()

# Pipeline completo
app.run_full_pipeline()
```

## Estrutura de Dados

### Posts CSV

```csv
post_type,title,cover_image,link,resumo,data_resumo
Product,Article Title,https://...,https://...,Resumo do post...,09/12/2025 14:30
```

### Resumos JSON

```json
[
  {
    "titulo": "Article Title",
    "link": "https://...",
    "data": "09/12/2025 14:30",
    "conteudo": "Resumo profissional..."
  }
]
```

## Logs

Os logs s√£o armazenados em `logs/application.log` com rota√ß√£o autom√°tica:

- N√≠vel: INFO (configur√°vel)
- Formato: `timestamp - module - level - message`
- Rota√ß√£o: 10MB por arquivo, 5 backups
- **Sem emojis** - logs profissionais

## Banco de Dados

SQLite em `database/resumos_processados.db`:

- Rastreia posts j√° processados
- Previne reprocessamento desnecess√°rio
- Estat√≠sticas de uso

## Melhores Pr√°ticas Implementadas

### C√≥digo

- ‚úÖ Programa√ß√£o Orientada a Objetos
- ‚úÖ Separa√ß√£o de responsabilidades (SRP)
- ‚úÖ Type hints em todas as fun√ß√µes
- ‚úÖ Documenta√ß√£o completa (docstrings)
- ‚úÖ Tratamento robusto de exce√ß√µes
- ‚úÖ Logging estruturado e profissional
- ‚úÖ Configura√ß√µes externalizadas

### Arquitetura

- ‚úÖ Padr√£o Singleton para configura√ß√£o
- ‚úÖ Context managers para recursos
- ‚úÖ Factory pattern para loggers
- ‚úÖ Modulariza√ß√£o clara
- ‚úÖ Baixo acoplamento

### Operacional

- ‚úÖ Logs sem emojis (requisito do projeto)
- ‚úÖ Versionamento Git adequado
- ‚úÖ Documenta√ß√£o t√©cnica completa
- ‚úÖ Estrutura de diret√≥rios padronizada
- ‚úÖ Rastreabilidade de execu√ß√µes

## Solu√ß√£o de Problemas

### Erro: "OPENAI_API_KEY n√£o configurada"

Configure a vari√°vel de ambiente no arquivo `.env`

### Erro: "Arquivo config.ini n√£o encontrado"

Certifique-se de que `config.ini` est√° na raiz do projeto

### Chrome Driver n√£o encontrado

O webdriver-manager baixa automaticamente. Verifique conex√£o internet.

### Posts n√£o sendo processados

Verifique:
1. Posts j√° foram processados? (banco de dados)
2. Logs em `logs/application.log`
3. CSV existe e est√° v√°lido?

## Estat√≠sticas

Ao final da execu√ß√£o, o sistema exibe:

- Total de posts extra√≠dos
- Posts com/sem resumo
- Distribui√ß√£o por tipo
- Posts processados hoje
- Resumos armazenados

## Contribui√ß√£o

1. Siga as diretrizes do Prompt Base
2. Mantenha logs sem emojis
3. Documente mudan√ßas em `docs/`
4. Fa√ßa commits descritivos
5. Teste antes de commitar

## Licen√ßa

Copyright ¬© 2025 - Sistema AFN

## Docker - Recursos Avan√ßados

### Personalizar Agendamento

Edite `.env` e ajuste `SCHEDULE_CRON`:

| Descri√ß√£o | Express√£o Cron |
|-----------|----------------|
| Segunda-feira 08:00 (padr√£o) | `0 8 * * 1` |
| Segunda a Sexta 09:00 | `0 9 * * 1-5` |
| Todos os dias 10:00 | `0 10 * * *` |
| A cada 6 horas | `0 */6 * * *` |

### Volumes Persistentes

```
logs/       ‚Üí Logs da aplica√ß√£o
database/   ‚Üí Banco de dados SQLite
graphics/   ‚Üí Gr√°ficos gerados
reports/    ‚Üí Relat√≥rios
dados/      ‚Üí Datasets
```

### Documenta√ß√£o Docker

- **In√≠cio R√°pido**: `DOCKER_QUICKSTART.md`
- **Guia Completo**: `docs/GUIA_DOCKER.md`
- **Implementa√ß√£o T√©cnica**: `docs/IMPLEMENTACAO_DOCKER_2025-12-09.md`

---

## Suporte

Para d√∫vidas ou problemas:
1. Consulte logs em `logs/application.log`
2. Verifique documenta√ß√£o em `docs/`
3. Analise c√≥digo fonte (bem documentado)
4. Docker: `docker-compose logs -f`

---

**Desenvolvido seguindo os princ√≠pios de:**
- Clareza e simplicidade
- Escalabilidade
- Manutenibilidade
- Rastreabilidade
- Excel√™ncia t√©cnica

